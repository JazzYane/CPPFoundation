4.单变量线性回归
4.1监督学习：“机器学习速成课程” https://developers.google.cn/machine-learning/crash-course/
4.1.1简单的线性回归案例：y = w*x + b
4.1.2术语：
标签：我们要预测的真实事物：y线性回归中的y变量
特征：描述数据的输入变量：xi 线性回归中的{x1,x2,…,xn}变量
样本：数据的特定实例：x
有标签样本具有{特征，标签}：{x，y}，用于训练模型；无标签样本具有{特征，？}：{x，?}，用于对新数据做出预测
模型：可将样本映射到预测标签：y’  由模型的内部参数定义，这些内部参数值是通过学习得到的
训练：模型表示通过有标签样本来学习（确定）所有权重和偏差的理想值
在监督式学习中，机器学习算法通过以下方式构建模型：检查多个样本并尝试找出可最大限度地减少损失的模型，这一过程称为经验风险最小化
损失：损失是对糟糕预测的惩罚：损失是一个数值，表示对于单个样本而言模型预测的准确程度
训练模型的目标是从所有样本中找到一组平均损失“较小”的权重和偏差
定义损失函数：
L1损失：基于模型预测的值与标签的实际值之差的绝对值
平方损失：一种常见的损失函数，又称为 L2 损失 
均方误差 (MSE) 指的是每个样本的平均平方损失
4.1.3训练模型的迭代方法
4.1.4模型训练要点：首先对权重w和偏差b进行初始猜测，然后反复调整这些猜测，直到获得损失可能最低的权重和偏差为止
4.1.5收敛：在学习优化过程中，机器学习系统将根据所有标签去重新评估所有特征，为损失函数生成一个新值，而该值又产生新的参数值。
通常，您可以不断迭代，直到总体损失不再变化或至少变化极其缓慢为止。这时候，我们可以说该模型已收敛
4.1.6计算损失例子
pred = w*x + b
该线性回归问题产生的损失与权重图为凸形 凸形问题只有一个最低点；即只存在一个斜率正好为 0 的位置 这个最小值就是损失函数收敛之处 
梯度下降法：
梯度：一个向量（矢量），表示某一函数在该点处的方向导数沿着 该方向取得最大值，即函数在该点处沿着该方向（此梯度的方向） 变化最快，变化率最大
梯度是矢量:具有方向和大小
用梯度乘以一个称为学习速率 （有时也称为步长）的标量， 以确定下一个点的位置
超参数：在机器学习中，超参数是在开始学习过程之前设置值的参数，而不 是通过训练得到的参数数据，通常情况下，需要对超参数进行优化，选择一组好的超参数，可以 提高学习的性能和效果
超参数是编程人员在机器学习算法中用于调整的旋钮
学习率、神经网络的隐含层数量……
4.2线性回归问题TensorFlow实战
核心步骤：准备数据、构建模型、训练模型、进行预测
实际步骤：
